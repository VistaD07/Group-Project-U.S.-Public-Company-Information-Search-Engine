{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Group Project: U.S. Public Company Information Search Engine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1: NoSQL Database Setup and Flask Design**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stock Data Acquisition: Get dataset from Yahoo_fin library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yahoo_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read file\n",
    "ticker_df = pd.read_csv('combined_ticker.csv')\n",
    "\n",
    "# Extract the 'Symbol' column, which is the first column containing the stock tickers\n",
    "company_tickers = ticker_df['Symbol'].tolist()\n",
    "\n",
    "# Print the list to verify\n",
    "print(company_tickers[:20])  # Prints the first 10 stock tickers as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data\n",
    "\n",
    "# Define the start and end dates in MM/DD/YYYY format\n",
    "start_date = \"04/08/2014\"\n",
    "end_date = \"04/08/2024\"\n",
    "\n",
    "# Initialize a list to store the data from each ticker\n",
    "all_data_list = []\n",
    "\n",
    "for ticker in company_tickers:\n",
    "    try:\n",
    "        # Fetch all available historical data for each ticker within the specified date range\n",
    "        data = get_data(ticker, start_date=start_date, end_date=end_date, index_as_date=True, interval=\"1d\")\n",
    "        # Add a 'ticker' column to identify the source ticker\n",
    "        data['ticker'] = ticker\n",
    "        # Append this DataFrame to the list\n",
    "        all_data_list.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "\n",
    "# Concatenate all the DataFrames in the list into a single DataFrame\n",
    "all_data = pd.concat(all_data_list)\n",
    "\n",
    "# Now, all_data is a single DataFrame with each row containing the open, high, low, close, adjusted close, volume, and ticker\n",
    "print(all_data.head())  # Display the first few rows to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'companies_stockprices_2014_to_2024.csv'\n",
    "all_data.to_csv(csv_file_path)\n",
    "all_stock = pd.read_csv('companies_stockprices_2014_to_2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_24673/1605912055.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>high_low_diff</th>\n",
       "      <th>close_open_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>A</td>\n",
       "      <td>35.86</td>\n",
       "      <td>2575815.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-09</td>\n",
       "      <td>A</td>\n",
       "      <td>36.54</td>\n",
       "      <td>2820465.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-10</td>\n",
       "      <td>A</td>\n",
       "      <td>35.54</td>\n",
       "      <td>2749027.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>A</td>\n",
       "      <td>34.70</td>\n",
       "      <td>3623616.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>A</td>\n",
       "      <td>34.62</td>\n",
       "      <td>3971159.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker  adjclose     volume  high_low_diff  close_open_diff\n",
       "0  2014-04-08      A     35.86  2575815.0           0.84             0.32\n",
       "1  2014-04-09      A     36.54  2820465.0           0.88             0.09\n",
       "2  2014-04-10      A     35.54  2749027.0           1.24            -1.09\n",
       "3  2014-04-11      A     34.70  3623616.0           1.00            -0.66\n",
       "4  2014-04-14      A     34.62  3971159.0           0.67            -0.39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_stock = pd.read_csv('companies_stockprices_2014_to_2024.csv')\n",
    "\n",
    "all_stock['high_low_diff'] = all_stock['high'] - all_stock['low']\n",
    "all_stock['close_open_diff'] = all_stock['close'] - all_stock['open']\n",
    "\n",
    "all_stock = all_stock.drop(columns=['open', 'high', 'low', 'close'])\n",
    "all_stock = all_stock.rename(columns={'Unnamed: 0': 'date'})\n",
    "\n",
    "all_stock['adjclose'] = all_stock['adjclose'].round(2)\n",
    "all_stock['high_low_diff'] = all_stock['high_low_diff'].round(2)\n",
    "all_stock['close_open_diff'] = all_stock['close_open_diff'].round(2)\n",
    "\n",
    "all_stock = all_stock[['date', 'ticker', 'adjclose', 'volume', 'high_low_diff', 'close_open_diff']]\n",
    "\n",
    "all_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = all_stock.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Insert data into NoSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost',27017)\n",
    "db = client.apan5400\n",
    "collection = db.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.insert_many(data_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Design user interaction pages with Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, jsonify, redirect, url_for, session\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'apan5400_group_project'\n",
    "\n",
    "ticker_df = pd.read_csv('combined_ticker.csv')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/search_ticker', methods=['GET'])\n",
    "def search_ticker():\n",
    "    query = request.args.get('q', '').upper()\n",
    "    if query:\n",
    "        matched = ticker_df[ticker_df['Symbol'].str.startswith(query)]['Symbol'].tolist()\n",
    "        return jsonify(matched)\n",
    "    return jsonify([])\n",
    "\n",
    "@app.route('/search', methods=['POST'])\n",
    "def search():\n",
    "    ticker = request.form['ticker']\n",
    "    start_date = request.form['start_date']\n",
    "    end_date = request.form['end_date']\n",
    "\n",
    "    query_result = perform_stock_price_query(ticker, start_date, end_date)\n",
    "\n",
    "    session['query_result'] = json.dumps(query_result, default=str)\n",
    "    session['ticker'] = ticker  \n",
    "    return redirect(url_for('show_results'))\n",
    "\n",
    "def perform_stock_price_query(ticker, start_date, end_date):\n",
    "    \n",
    "    client = MongoClient('localhost', 27017)\n",
    "    db = client['apan5400']\n",
    "    collection = db['project']\n",
    "    \n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"ticker\": ticker,\n",
    "                \"date\": {\n",
    "                    \"$gte\": start_date,\n",
    "                    \"$lte\": end_date\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"date\": 1,\n",
    "                \"adjclose\": 1,\n",
    "                \"volume\": 1,\n",
    "                \"high_low_diff\": 1,\n",
    "                \"close_open_diff\": 1\n",
    "            }\n",
    "        },\n",
    "        {\"$sort\": {\"date\": 1}}\n",
    "    ]\n",
    "    try:\n",
    "        return list(collection.aggregate(pipeline))\n",
    "    except Exception as e:\n",
    "        app.logger.error(\"Query failed: %s\", e)\n",
    "        return []\n",
    "\n",
    "@app.route('/results')\n",
    "def show_results():\n",
    "    data = json.loads(session.get('query_result', '[]'))\n",
    "    ticker = session.get('ticker', 'Unknown Ticker')  \n",
    "    return render_template('results.html', data=data, ticker=ticker)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2: SQL Database Setup and Flask Design**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Financial Data Acquisition: Get three datasets from WRDS Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Company Information Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install psycopg2-binary\n",
    "#%pip install io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "# Load the first few rows of the CSV files to inspect their structure\n",
    "company_info_path = 'company info.csv'\n",
    "company_info_df = pd.read_csv(company_info_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique.drop(columns=['ipodate'], inplace=True)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique['phone'] = company_info_df_unique['phone'].apply(clean_phone_number).apply(format_phone_number)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  company_info_df_unique['fyear'].fillna(0, inplace=True)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique['fyear'].fillna(0, inplace=True)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique['fyear'] = company_info_df_unique['fyear'].astype(int)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  company_info_df_unique['cik'].fillna(0, inplace=True)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique['cik'].fillna(0, inplace=True)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique['cik'] = company_info_df_unique['cik'].astype(int)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  company_info_df_unique['spcindcd'].fillna(0, inplace=True)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique['spcindcd'].fillna(0, inplace=True)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique['spcindcd'] = company_info_df_unique['spcindcd'].astype(int)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique.fillna(value=np.nan, inplace=True)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n",
      "/var/folders/nm/brcjtfwd5yzclpnv14tsc7100000gn/T/ipykernel_62510/3926673727.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)\n"
     ]
    }
   ],
   "source": [
    "company_info_df_unique = company_info_df.drop_duplicates(subset='tic', keep='first')\n",
    "\n",
    "company_info_df_unique.drop(columns=['ipodate'], inplace=True)\n",
    "\n",
    "def clean_phone_number(phone):\n",
    "    if pd.isna(phone):\n",
    "        return None\n",
    "    return ''.join([char for char in str(phone) if char.isdigit()])\n",
    "\n",
    "def format_phone_number(phone):\n",
    "    if phone is None or len(phone) != 10:\n",
    "        return phone\n",
    "    return f'({phone[:3]}) {phone[3:6]}-{phone[6:]}'\n",
    "\n",
    "company_info_df_unique['phone'] = company_info_df_unique['phone'].apply(clean_phone_number).apply(format_phone_number)\n",
    "\n",
    "company_info_df_unique['fyear'].fillna(0, inplace=True)\n",
    "company_info_df_unique['fyear'] = company_info_df_unique['fyear'].astype(int)\n",
    "company_info_df_unique['cik'].fillna(0, inplace=True)\n",
    "company_info_df_unique['cik'] = company_info_df_unique['cik'].astype(int)\n",
    "company_info_df_unique['spcindcd'].fillna(0, inplace=True)\n",
    "company_info_df_unique['spcindcd'] = company_info_df_unique['spcindcd'].astype(int)\n",
    "\n",
    "company_info_df_unique.fillna(value=np.nan, inplace=True)\n",
    "\n",
    "for col in company_info_df_unique.columns:\n",
    "    if company_info_df_unique[col].dtype == 'object' or pd.api.types.is_datetime64_any_dtype(company_info_df_unique[col]):\n",
    "        company_info_df_unique[col] = company_info_df_unique[col].where(company_info_df_unique[col].notnull(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "company_overview_dict = {\n",
    "    \"gvkey\": \"Global Company Key\",\n",
    "    \"datadate\": \"Public Date\",\n",
    "    \"fyear\": \"Fiscal Year\",\n",
    "    \"tic\": \"Ticker\",\n",
    "    \"conm\": \"Company Name\",\n",
    "    \"curcd\": \"Native Currency\",\n",
    "    \"cik\": \"CIK number\",\n",
    "    \"add1\": \"Company Address\",\n",
    "    \"addzip\": \"Zip code\",\n",
    "    \"busdesc\": \"S&P Business Description\",\n",
    "    \"city\": \"City\",\n",
    "    \"conml\": \"Company Legal Name\",\n",
    "    \"county\": \"Country\",\n",
    "    \"phone\": \"Company Contact\",\n",
    "    \"spcindcd\": \"S&P Industry Sector Code\",\n",
    "    \"state\": \"State\",\n",
    "    \"weburl\": \"Company Website\"\n",
    "}\n",
    "\n",
    "company_info = pd.DataFrame(list(company_overview_dict.items()), columns=['Abbreviation', 'Full Name'])\n",
    "\n",
    "company_info.to_csv('company_overview_dict.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Annual Financials Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gvkey    datadate   fyear indfmt consol popsrc datafmt  tic      conm  \\\n",
      "0   1004  2014-05-31  2013.0   INDL      C      D     STD  AIR  AAR CORP   \n",
      "1   1004  2015-05-31  2014.0   INDL      C      D     STD  AIR  AAR CORP   \n",
      "2   1004  2016-05-31  2015.0   INDL      C      D     STD  AIR  AAR CORP   \n",
      "3   1004  2017-05-31  2016.0   INDL      C      D     STD  AIR  AAR CORP   \n",
      "4   1004  2018-05-31  2017.0   INDL      C      D     STD  AIR  AAR CORP   \n",
      "\n",
      "  curcd  ...  intan   invt  ist  lcat    lct  niint  opiti   rect    seq  \\\n",
      "0   USD  ...  440.1  632.9  NaN   NaN  402.1    NaN    NaN  297.9  999.5   \n",
      "1   USD  ...  172.4  566.7  NaN   NaN  412.0    NaN    NaN  231.1  845.1   \n",
      "2   USD  ...  168.6  563.7  NaN   NaN  329.0    NaN    NaN  242.7  865.8   \n",
      "3   USD  ...  162.6  601.1  NaN   NaN  335.1    NaN    NaN  251.4  914.2   \n",
      "4   USD  ...  157.1  547.9  NaN   NaN  333.3    NaN    NaN  203.0  936.3   \n",
      "\n",
      "   costat  \n",
      "0       A  \n",
      "1       A  \n",
      "2       A  \n",
      "3       A  \n",
      "4       A  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "financials = pd.read_csv('financials.csv')\n",
    "print(financials.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 NaN values in the fyear column.\n"
     ]
    }
   ],
   "source": [
    "nan_count = financials['fyear'].isna().sum()\n",
    "print(f'Found {nan_count} NaN values in the fyear column.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gvkey    datadate  fyear indfmt consol popsrc datafmt  tic      conm curcd  \\\n",
      "0   1004  2014-05-31   2013   INDL      C      D     STD  AIR  AAR CORP   USD   \n",
      "1   1004  2015-05-31   2014   INDL      C      D     STD  AIR  AAR CORP   USD   \n",
      "2   1004  2016-05-31   2015   INDL      C      D     STD  AIR  AAR CORP   USD   \n",
      "3   1004  2017-05-31   2016   INDL      C      D     STD  AIR  AAR CORP   USD   \n",
      "4   1004  2018-05-31   2017   INDL      C      D     STD  AIR  AAR CORP   USD   \n",
      "\n",
      "   ...  intan   invt  ist  lcat    lct  niint  opiti   rect    seq  costat  \n",
      "0  ...  440.1  632.9  NaN   NaN  402.1    NaN    NaN  297.9  999.5       A  \n",
      "1  ...  172.4  566.7  NaN   NaN  412.0    NaN    NaN  231.1  845.1       A  \n",
      "2  ...  168.6  563.7  NaN   NaN  329.0    NaN    NaN  242.7  865.8       A  \n",
      "3  ...  162.6  601.1  NaN   NaN  335.1    NaN    NaN  251.4  914.2       A  \n",
      "4  ...  157.1  547.9  NaN   NaN  333.3    NaN    NaN  203.0  936.3       A  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "financials = financials.dropna(subset=['fyear'])\n",
    "financials['fyear'] = financials['fyear'].astype(int)\n",
    "print(financials.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_delete = ['datadate','indfmt', 'consol', 'popsrc', 'datafmt','curcd','fyr','acqniintc','costat']\n",
    "financials = financials.drop(columns=columns_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gvkey  fyear  tic      conm     act     ap      at   bkvlps    cogs   dlc  \\\n",
      "0   1004   2013  AIR  AAR CORP  1116.9  171.1  2199.5  25.2654  1581.4  69.7   \n",
      "1   1004   2014  AIR  AAR CORP   954.1  142.3  1515.0  23.8574  1342.7  69.0   \n",
      "2   1004   2015  AIR  AAR CORP   873.1  163.4  1442.1  25.0847  1354.9  12.0   \n",
      "3   1004   2016  AIR  AAR CORP   888.5  177.4  1504.1  26.6112  1422.7   2.0   \n",
      "4   1004   2017  AIR  AAR CORP   942.7  170.0  1524.7  26.9703  1413.2   0.0   \n",
      "\n",
      "   ...   dvc  intan   invt  ist  lcat    lct  niint  opiti   rect    seq  \n",
      "0  ...  11.8  440.1  632.9  NaN   NaN  402.1    NaN    NaN  297.9  999.5  \n",
      "1  ...  11.9  172.4  566.7  NaN   NaN  412.0    NaN    NaN  231.1  845.1  \n",
      "2  ...  10.4  168.6  563.7  NaN   NaN  329.0    NaN    NaN  242.7  865.8  \n",
      "3  ...  10.2  162.6  601.1  NaN   NaN  335.1    NaN    NaN  251.4  914.2  \n",
      "4  ...  10.3  157.1  547.9  NaN   NaN  333.3    NaN    NaN  203.0  936.3  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(financials.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials = financials.drop_duplicates(subset=['tic', 'fyear'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'financials_processed.csv'\n",
    "financials.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fyear': 'Data Year - Fiscal', 'tic': 'Ticker Symbol', 'conm': 'Company Name', 'act': 'Current Assets - Total', 'ap': 'Accounts Payable - Trade', 'at': 'Assets - Total', 'bkvlps': 'Book Value Per Share', 'cogs': 'Cost of Goods Sold', 'dlc': 'Debt in Current Liabilities - Total', 'dltt': 'Long Term Debt - Total', 'dptb': 'Deposits - Total - Banks', 'dvc': 'Dividends Common/Ordinary', 'intan': 'Intangible Assets - Total', 'invt': 'Inventories - Total', 'ist': 'Investment Securities - Total', 'lcat': 'Loans/Claims/Advances - Total', 'lct': 'Current Liabilities - Total', 'niint': 'Net Interest Income', 'opiti': 'Operating Income - Total', 'rect': 'Receivables - Total', 'seq': 'Stockholders Equity - Parent'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Explain variables\n",
    "financials_var = pd.read_excel('financials_list.xlsx')\n",
    "\n",
    "financials_dict = pd.Series(financials_var.iloc[:, 1].values, index=financials_var.iloc[:, 0].values).to_dict()\n",
    "\n",
    "print(financials_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Monthly Financial Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"ratio data.csv\")\n",
    "\n",
    "# Replace NA values with 0 and round off with two decimal places\n",
    "data.iloc[:, 3:33] = data.iloc[:, 3:33].apply(lambda x: x.fillna(0).round(2))\n",
    "data.to_csv(\"ratios.csv\", index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"ratios.csv\")\n",
    "\n",
    "\n",
    "# Convert the 'public_date' column to datetime format and extract the year and month\n",
    "df['public_date'] = pd.to_datetime(df['public_date'])\n",
    "df['year'] = df['public_date'].dt.year\n",
    "df['month'] = df['public_date'].dt.month\n",
    "\n",
    "# Drop public_date column\n",
    "df = df.drop(columns=['public_date'])\n",
    "\n",
    "# 再次保存数据\n",
    "df.to_csv(\"ratios.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "financial_ratios_full_names = {\n",
    "    \"bm\": \"Book/Market ratio\",\n",
    "    \"evm\": \"Enterprise Multiple (EV/EBITDA) ratio\",\n",
    "    \"pe_op_basic\": \"Price/Operating Earnings ratio\",\n",
    "    \"ps\": \"Price/Sales\",\n",
    "    \"pcf\": \"Price/Cash Flow\",\n",
    "    \"dpr\": \"Dividend Payout ratio\",\n",
    "    \"npm\": \"Net profit margin\",\n",
    "    \"gpm\": \"Gross profit margin\",\n",
    "    \"roa\": \"Return on Assets\",\n",
    "    \"roe\": \"Return on Equity\",\n",
    "    \"efftax\": \"Effective Tax Rate\",\n",
    "    \"aftret_eq\": \"After-Tax Return on Average Common Equity\",\n",
    "    \"equity_invcap\": \"Common Equity/Invested Capital\",\n",
    "    \"debt_invcap\": \"Long-term Debt/Invested Capital\",\n",
    "    \"totdebt_invcap\": \"Total Debt/Invested Capital\",\n",
    "    \"capital_ratio\": \"Capitalization Ratio\",\n",
    "    \"debt_ebitda\": \"Total Debt/EBITDA\",\n",
    "    \"debt_assets\": \"Total Debt/Total Assets\",\n",
    "    \"de_ratio\": \"Total Debt/Equity\",\n",
    "    \"cash_conversion\": \"Cash Conversion Cycle\",\n",
    "    \"inv_turn\": \"Inventory Turnover\",\n",
    "    \"at_turn\": \"Asset Turnover\",\n",
    "    \"sale_equity\": \"Sales/Stockholders Equity\",\n",
    "    \"rd_sale\": \"R&D Expense/Sales\",\n",
    "    \"adv_sale\": \"Advertising Expense/Sales\",\n",
    "    \"staff_sale\": \"Labor Expense/Sales\",\n",
    "    \"accrual\": \"Accruals/Average Assets\",\n",
    "    \"ptb\": \"Price/Book\",\n",
    "    \"peg_trailing\": \"Trailing P/E to Growth ratio\",\n",
    "    \"divyield\": \"Dividend Yield\"\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(list(financial_ratios_full_names.items()), columns=['Abbreviation', 'Full Name'])\n",
    "\n",
    "df.to_csv('ratios_dict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Insert data into SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Company Information Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from io import StringIO\n",
    "\n",
    "params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": '5432',\n",
    "    \"dbname\": \"my_db\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123\"\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE company_info (\n",
    "    gvkey INT,\n",
    "    datadate DATE,\n",
    "    fyear INT,\n",
    "    indfmt VARCHAR(20),\n",
    "    consol CHAR(1),\n",
    "    popsrc CHAR(1),\n",
    "    datafmt VARCHAR(20),\n",
    "    tic VARCHAR(255) PRIMARY KEY,\n",
    "    conm VARCHAR(255),\n",
    "    curcd CHAR(3),\n",
    "    cik INT,\n",
    "    costat VARCHAR(10),\n",
    "    add1 VARCHAR(255),\n",
    "    addzip VARCHAR(20),\n",
    "    busdesc TEXT,\n",
    "    city VARCHAR(255),\n",
    "    conml VARCHAR(255),\n",
    "    county VARCHAR(255),\n",
    "    phone VARCHAR(20),\n",
    "    spcindcd INT,\n",
    "    state VARCHAR(50),\n",
    "    weburl VARCHAR(255)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "df = company_info_df_unique  \n",
    "\n",
    "output = StringIO()\n",
    "df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "output.seek(0) \n",
    "\n",
    "cur.copy_from(output, 'company_info', null=\"NULL\", columns=df.columns.tolist())\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Annual Financials Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"my_db\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE financials (\n",
    "    gvkey INT,\n",
    "    fyear INT,\n",
    "    tic VARCHAR(10),\n",
    "    conm VARCHAR(255),\n",
    "    act NUMERIC(10, 2),\n",
    "    ap NUMERIC(10, 2),\n",
    "    at NUMERIC(10, 2),\n",
    "    bkvlps NUMERIC(10, 2),\n",
    "    cogs NUMERIC(10, 2),\n",
    "    dlc NUMERIC(10, 2),\n",
    "    dltt NUMERIC(10, 2),\n",
    "    dptb NUMERIC(10, 2),\n",
    "    dvc NUMERIC(10, 2),\n",
    "    intan NUMERIC(10, 2),\n",
    "    invt NUMERIC(10, 2),\n",
    "    ist NUMERIC(10, 2),\n",
    "    lcat NUMERIC(10, 2),\n",
    "    lct NUMERIC(10, 2),\n",
    "    niint NUMERIC(10, 2),\n",
    "    opiti NUMERIC(10, 2),\n",
    "    rect NUMERIC(10, 2),\n",
    "    seq NUMERIC(10, 2),\n",
    "    PRIMARY KEY(tic, fyear)\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# delete the first column manually before loading\n",
    "financial_df = pd.read_csv('financials_processed.csv')\n",
    "\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO financials (\n",
    "    gvkey, fyear, tic, conm, act, ap, at, bkvlps, cogs, dlc, dltt, dptb, dvc, intan,\n",
    "    invt, ist, lcat, lct, niint, opiti, rect, seq\n",
    ") VALUES %s;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tuples = [tuple(x) for x in financial_df.to_numpy()]\n",
    "\n",
    "\n",
    "extras.execute_values(cur, insert_query, tuples, template=None, page_size=100)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Monthly Financial Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the PostgreSQL database.\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy\n",
    "\n",
    "financial_ratios_csv_path = 'ratios.csv'\n",
    "\n",
    "engine = create_engine('postgresql://postgres:123@localhost:5432/my_db')\n",
    "\n",
    "try:\n",
    "    conn = psycopg.connect(\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "        dbname=\"my_db\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\"\n",
    "    )\n",
    "    print(\"Connected to the PostgreSQL database.\")\n",
    "except psycopg.Error as e:\n",
    "    print(\"Error: Could not connect to PostgreSQL database.\")\n",
    "    print(e)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "financial_ratios_data = pd.read_csv(financial_ratios_csv_path)\n",
    "financial_ratios_data.columns = financial_ratios_data.columns.str.lower() \n",
    "financial_ratios_data.to_sql('financial_ratios', engine, if_exists='replace', index=False)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"ALTER TABLE financial_ratios ADD PRIMARY KEY (ticker, year, month);\")\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Design user interaction pages with Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, jsonify, redirect, url_for, session\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'apan5400_group_project'\n",
    "\n",
    "df = pd.read_csv('data/combined_ticker copy.csv')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/search_ticker', methods=['GET'])\n",
    "def search_ticker():\n",
    "    query = request.args.get('q', '').upper()\n",
    "    if query:\n",
    "        matched = df[df['Symbol'].str.startswith(query)]['Symbol'].tolist()\n",
    "        return jsonify(matched)\n",
    "    return jsonify([])\n",
    "\n",
    "@app.route('/search', methods=['POST'])\n",
    "def search():\n",
    "    ticker = request.form['ticker']\n",
    "    info_type = request.form['info_type']\n",
    "    session['ticker'] = ticker\n",
    "    session['info_type'] = info_type\n",
    "    return redirect(url_for('display_options'))\n",
    "\n",
    "@app.route('/display_options')\n",
    "def display_options():\n",
    "    info_type = session.get('info_type', 'company_overview')\n",
    "    dict_file = {\n",
    "        'company_overview': 'data/company_overview_dict.csv',\n",
    "        'financial_statements': 'data/annual_financial_dict.csv',\n",
    "        'key_ratios': 'data/key_ratios_dict.csv'\n",
    "    }.get(info_type, 'data/company_overview_dict.csv')\n",
    "    data = pd.read_csv(dict_file)\n",
    "    options = data.iloc[:, 1].dropna().tolist()\n",
    "    return render_template('display_options.html', options=options, info_type=info_type)\n",
    "\n",
    "@app.route('/results', methods=['POST'])\n",
    "def results():\n",
    "    ticker = session['ticker']\n",
    "    info_type = session['info_type']\n",
    "    selected_options = request.form.getlist('selected_options')\n",
    "    data = []\n",
    "    fiscal_year = request.form.get('fiscalYear')\n",
    "    start_month = request.form.get('startMonth', None) \n",
    "    end_month = request.form.get('endMonth', None)      \n",
    "\n",
    "    if info_type == 'company_overview':\n",
    "        data = perform_query_company_overview(ticker, selected_options)\n",
    "    elif info_type == 'financial_statements':\n",
    "        data = perform_query_financial_statements(ticker, selected_options, fiscal_year)\n",
    "    elif info_type == 'key_ratios':\n",
    "        data = perform_query_key_ratios(ticker, selected_options, fiscal_year, start_month, end_month)\n",
    "    \n",
    "    return render_template('results.html', \n",
    "                           ticker=ticker, \n",
    "                           info_type=info_type, \n",
    "                           data=data, \n",
    "                           variables=selected_options,\n",
    "                           fiscal_year=fiscal_year,\n",
    "                           start_month=start_month,\n",
    "                           end_month=end_month)\n",
    "\n",
    "\n",
    "def perform_query_company_overview(ticker, variables):\n",
    "    return query_database(ticker, variables, 'company_info', 'company_overview')\n",
    "\n",
    "\n",
    "def perform_query_financial_statements(ticker, variables, fiscal_year):\n",
    "    return query_database(ticker, variables, 'financials', 'financial_statements', extra_conditions=\"fyear = %s\", extra_params=[fiscal_year])\n",
    "\n",
    "\n",
    "def perform_query_key_ratios(ticker, variables, fiscal_year, start_month, end_month):\n",
    "    return query_database(ticker, variables, 'financial_ratios', 'key_ratios', extra_conditions=\"year = %s AND month BETWEEN %s AND %s\", extra_params=[fiscal_year, start_month, end_month])\n",
    "\n",
    "\n",
    "def load_variable_mapping(info_type):\n",
    "    dict_file = {\n",
    "        'company_overview': 'data/company_overview_dict.csv',\n",
    "        'financial_statements': 'data/annual_financial_dict.csv',\n",
    "        'key_ratios': 'data/key_ratios_dict.csv'\n",
    "    }.get(info_type, 'data/company_overview_dict.csv')\n",
    "\n",
    "    \n",
    "    mapping_df = pd.read_csv(dict_file)\n",
    "    return dict(zip(mapping_df.iloc[:, 1], mapping_df.iloc[:, 0]))\n",
    "\n",
    "def query_database(ticker, variables, table, info_type, extra_conditions=None, extra_params=[]):\n",
    "   \n",
    "    variable_mapping = load_variable_mapping(info_type)\n",
    "\n",
    "   \n",
    "    db_columns = [variable_mapping.get(var, var) for var in variables]\n",
    "\n",
    "    \n",
    "    params = {\"host\": \"localhost\", \"port\": '5432', \"dbname\": \"my_db\", \"user\": \"postgres\", \"password\": \"123\"}\n",
    "    conn = psycopg2.connect(**params)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    \n",
    "    sql_fields = sql.SQL(', ').join(map(sql.Identifier, db_columns))\n",
    "    sql_table = sql.Identifier(table)\n",
    "\n",
    "  \n",
    "    query = sql.SQL(\"SELECT {fields} FROM {table} WHERE ticker = %s\").format(\n",
    "        fields=sql_fields,\n",
    "        table=sql_table\n",
    "    )\n",
    "\n",
    "   \n",
    "    if extra_conditions:\n",
    "        query = sql.SQL(\"{} AND {}\").format(query, sql.SQL(extra_conditions))\n",
    "\n",
    "    \n",
    "    try:\n",
    "        cur.execute(query, [ticker] + extra_params)\n",
    "        rows = cur.fetchall()\n",
    "        return [{var: val for var, val in zip(variables, row)} for row in rows]\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def month_name_filter(month_number):\n",
    "    if month_number:\n",
    "        month_number = int(month_number)\n",
    "        return datetime(1900, month_number, 1).strftime('%B')\n",
    "    return \"No month provided\"\n",
    "\n",
    "app.jinja_env.filters['month_name'] = month_name_filter\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
